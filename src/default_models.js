window.defaultModels = {
  "gpt-4o": {
    label: "GPT-4o standard",
    deployment: "gpt-4o-3",
    provider: "azure",
    context_length: 120000,
    max_tokens: 8000,
    temperature: 0.9,
    frequency_penalty: 0,
    presence_penalty: 0,
    system: true,
  },
  "openai-gpt-3.5": {
    label: "OpenAI GPT-3.5 Turbo",
    deployment: "gpt-3.5-turbo",
    provider: "openai",
    context_length: 4096,
    max_tokens: 2048,
    temperature: 0.7,
    system: true,
  },
  "openai-gpt-4": {
    label: "OpenAI GPT-4",
    deployment: "gpt-4",
    provider: "openai",
    context_length: 8192,
    max_tokens: 4096,
    temperature: 0.7,
    system: true,
  },
  "anthropic-claude": {
    label: "Anthropic Claude",
    deployment: "claude-v1",
    provider: "anthropic",
    context_length: 100000,
    max_tokens: 4000,
    temperature: 0.7,
    system: false,
  },
  "ollama-llama2": {
    label: "Llama 2 (Ollama)",
    deployment: "llama2",
    provider: "ollama",
    context_length: 4096,
    max_tokens: 2048,
    temperature: 0.7,
    system: true,
  },
  o1: {
    label: "O1",
    deployment: "o1",
    provider: "azure",
    context_length: 120000,
    system: false,
  },
};
